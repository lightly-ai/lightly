{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This example requires the following dependencies to be installed:\n",
    "pip install lightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Note: The model and training settings do not follow the reference settings\n",
    "from the paper. The settings are chosen such that the example can easily be\n",
    "run on a small dataset with a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from timm.models.vision_transformer import vit_small_patch16_224\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightly.loss import DINOLoss, IBOTPatchLoss, KoLeoLoss\n",
    "from lightly.models.modules import DINOProjectionHead, MaskedVisionTransformerTIMM\n",
    "from lightly.models.utils import (\n",
    "    random_block_mask,\n",
    "    update_drop_path_rate,\n",
    "    update_momentum,\n",
    ")\n",
    "from lightly.transforms.ibot_transform import IBOTTransform\n",
    "from lightly.utils.scheduler import cosine_schedule, linear_warmup_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_eval_module(module: Module) -> None:\n",
    "    \"\"\"Freeze the parameters of a module.\"\"\"\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "    module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBOT(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim: int = 8192,  # Output dimension of the projection head\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Backbones\n",
    "        vit_teacher = vit_small_patch16_224(\n",
    "            pos_embed=\"learn\",\n",
    "            dynamic_img_size=True,\n",
    "            init_values=1e-5,\n",
    "        )\n",
    "        self.teacher_backbone = MaskedVisionTransformerTIMM(\n",
    "            vit=vit_teacher,\n",
    "            antialias=False,\n",
    "            pos_embed_initialization=\"skip\",\n",
    "        )\n",
    "        self.student_backbone = copy.deepcopy(self.teacher_backbone)\n",
    "        update_drop_path_rate(\n",
    "            self.student_backbone.vit,\n",
    "            drop_path_rate=0.1,  # we recommend using smaller rates like 0.1 for vit-s-14\n",
    "            mode=\"uniform\",\n",
    "        )\n",
    "\n",
    "        freeze_eval_module(self.teacher_backbone)\n",
    "        self.embed_dim = self.student_backbone.vit.embed_dim\n",
    "\n",
    "        # Projection heads\n",
    "        projection_head = partial(\n",
    "            DINOProjectionHead,\n",
    "            input_dim=self.embed_dim,\n",
    "            output_dim=output_dim,\n",
    "        )\n",
    "\n",
    "        self.student_head = projection_head(norm_last_layer=False)\n",
    "        self.student_cls_head = self.student_patch_head = self.student_head\n",
    "\n",
    "        self.teacher_head = projection_head()\n",
    "        self.teacher_cls_head = self.teacher_patch_head = self.teacher_head\n",
    "\n",
    "        freeze_eval_module(self.teacher_head)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.teacher_backbone(x)\n",
    "\n",
    "    def forward_teacher(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        features = self.teacher_backbone.encode(x)\n",
    "        cls_tokens = features[:, 0]\n",
    "        return cls_tokens, features\n",
    "\n",
    "    def forward_student(\n",
    "        self, x: Tensor, mask: Tensor | None\n",
    "    ) -> tuple[Tensor, Tensor | None]:\n",
    "        features = self.student_backbone.encode(x, mask=mask)\n",
    "        cls_tokens = features[:, 0]\n",
    "        masked_features = None if mask is None else features[mask]\n",
    "        return cls_tokens, masked_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 8192\n",
    "model = IBOT(output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = IBOTTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We ignore object detection annotations by setting target_transform to return 0.\n",
    "def target_transform(t):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.VOCDetection(\n",
    "    \"datasets/pascal_voc\",\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "# Or create a dataset from a folder containing images or videos.\n",
    "# dataset = LightlyDataset(\"path/to/folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the loss functions.\n",
    "dino_criterion = DINOLoss(\n",
    "    output_dim=output_dim,\n",
    "    teacher_temp=0.07,\n",
    ")\n",
    "ibot_criterion = IBOTPatchLoss(\n",
    "    output_dim=output_dim,\n",
    "    teacher_temp=0.07,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move loss to correct device because it also contains parameters.\n",
    "dino_criterion = dino_criterion.to(device)\n",
    "ibot_criterion = ibot_criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "num_batches = len(dataloader)\n",
    "total_steps = epochs * num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Training\")\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        views = batch[0]\n",
    "        views = [view.to(device) for view in views]\n",
    "        global_views = torch.cat(views[:2])\n",
    "        local_views = torch.cat(views[2:])\n",
    "\n",
    "        # Masking\n",
    "        B = len(global_views)\n",
    "        sequence_length = model.teacher_backbone.sequence_length\n",
    "        mask = global_views.new_zeros((B, sequence_length), dtype=torch.bool)\n",
    "\n",
    "        # Mask patches except class token.\n",
    "        H, W = model.teacher_backbone.vit.patch_embed.grid_size\n",
    "        assert (\n",
    "            H * W == sequence_length - 1\n",
    "        ), f\"Unexpected grid size: {H}x{W}, sequence_length {sequence_length}\"\n",
    "        block_mask = random_block_mask(size=(B, H, W), device=mask.device)\n",
    "        mask[:, 1:] = block_mask.flatten(start_dim=1)\n",
    "\n",
    "        # Teacher forward\n",
    "        with torch.no_grad():\n",
    "            teacher_cls_token, teacher_features = model.forward_teacher(global_views)\n",
    "            teacher_cls_out = model.teacher_cls_head.forward(teacher_cls_token)\n",
    "            teacher_masked_out = model.teacher_patch_head.forward(\n",
    "                teacher_features[mask]\n",
    "            )\n",
    "\n",
    "        # Student forward\n",
    "        (\n",
    "            student_global_cls_token,\n",
    "            student_global_masked_features,\n",
    "        ) = model.forward_student(global_views, mask=mask)\n",
    "        student_global_cls_out = model.student_cls_head.forward(\n",
    "            student_global_cls_token\n",
    "        )\n",
    "        student_global_masked_out = model.student_patch_head.forward(\n",
    "            student_global_masked_features\n",
    "        )\n",
    "        student_local_cls_token, _ = model.forward_student(local_views, mask=None)\n",
    "        student_local_cls_out = model.student_cls_head.forward(student_local_cls_token)\n",
    "        student_cls_out = torch.cat([student_global_cls_out, student_local_cls_out])\n",
    "\n",
    "        # Calculate current global step based on epoch and batch index.\n",
    "        global_step = epoch * num_batches + batch_idx\n",
    "\n",
    "        # Calculate the loss.\n",
    "        teacher_temp = linear_warmup_schedule(\n",
    "            step=global_step,\n",
    "            warmup_steps=int(30 / epochs * total_steps),\n",
    "            start_value=0.04,\n",
    "            end_value=0.07,\n",
    "        )\n",
    "        dino_loss = dino_criterion(\n",
    "            teacher_out=teacher_cls_out.chunk(2),\n",
    "            student_out=student_cls_out.chunk(len(views)),\n",
    "            teacher_temp=teacher_temp,\n",
    "        )\n",
    "        ibot_loss = ibot_criterion(\n",
    "            teacher_out=teacher_masked_out,\n",
    "            student_out=student_global_masked_out,\n",
    "            mask=block_mask,\n",
    "            teacher_temp=teacher_temp,\n",
    "        )\n",
    "        loss = dino_loss + ibot_loss\n",
    "\n",
    "        total_loss += loss.detach()\n",
    "        loss.backward()\n",
    "\n",
    "        # Cancel gradients of the last layer of the student head\n",
    "        model.student_head.cancel_last_layer_gradients(epoch)\n",
    "\n",
    "        # Apply weight decay schedule.\n",
    "        weight_decay = cosine_schedule(\n",
    "            step=global_step,\n",
    "            max_steps=total_steps,\n",
    "            start_value=0.04,\n",
    "            end_value=0.4,\n",
    "        )\n",
    "\n",
    "        # Update weight decay directly for all parameter groups.\n",
    "        for group in optimizer.param_groups:\n",
    "            if group[\"weight_decay\"] != 0.0:\n",
    "                group[\"weight_decay\"] = weight_decay\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Momentum update teacher.\n",
    "        momentum = cosine_schedule(\n",
    "            step=global_step,\n",
    "            max_steps=total_steps,\n",
    "            start_value=0.992,\n",
    "            end_value=1.0,\n",
    "        )\n",
    "        update_momentum(model.student_backbone, model.teacher_backbone, m=momentum)\n",
    "        update_momentum(model.student_head, model.teacher_head, m=momentum)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
